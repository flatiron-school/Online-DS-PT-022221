{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Pipelines and Wrapping Up Phase 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Pipeline?\n",
    "\n",
    "Pipelines can keep our code neat and clean all the way from gathering & cleaning our data, to creating models & fine-tuning them!\n",
    "\n",
    "**Advantages**: \n",
    "- Reduces complexity\n",
    "- Convenient \n",
    "- Flexible \n",
    "- Can help prevent mistakes (like data leakage between train and test set) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easily integrate transformers and estimators, plus cross validation!\n",
    "\n",
    "<img src=\"images/grid_search_cross_validation.png\" alt=\"cross validation image from sklearn's documentation\" width=500>\n",
    "\n",
    "Why might CV be good in instances when we're doing things like searching for optimal hyperparameters...?\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, plot_confusion_matrix\n",
    "\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May need to install category_encoders if you'd like to use it:\n",
    "# !conda install -c conda-forge category_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data source: https://www.kaggle.com/c/cat-in-the-dat-ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab, then explore data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring numeric cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring object cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring target distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our X and y\n",
    "\n",
    "\n",
    "# and train test split - to create our val holdout set!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "\n",
    "Let's find out how hard our problem is, by throwing things at it and seeing what sticks!\n",
    "\n",
    "Biggest thing to think about - what types of columns need to be treated differently?\n",
    "\n",
    "Reference: https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up how to treat our columns\n",
    "\n",
    "# Want to grab numeric columns\n",
    "\n",
    "\n",
    "# Then grab columns with fewer than 10 unique values\n",
    "\n",
    "\n",
    "# Then grab columns with more than 10, since we won't OHE those\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check our work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, set up the preprocessing steps for each type of col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put together our preprocessor using a Column Transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just out of curiosity, let's see what this looks like \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate:\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Another Model Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for a new pipeline!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate:\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now how do we search using the pipeline? easily!\n",
    "# First - new dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define some parameters to test!\n",
    "# Note - need to include the name of what these params are for\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now put the pieces together\n",
    "\n",
    "# Can take a WHILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this to explore the scores of the params\n",
    "print(f\"Avg Train ROC-AUC for ---: {results.cv_results_['mean_train_score'][0]:.5f}\")\n",
    "print(\"*\" * 10)\n",
    "print(f\"Avg Test ROC-AUC for ---: {results.cv_results_['mean_test_score'][0]:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate\n",
    "\n",
    "How does this perform on our val set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(estimator, X_train, X_test, y_train, y_test, roc_auc='proba'):\n",
    "    '''\n",
    "    Evaluation function to show a few scores for both the train and test set\n",
    "    Also shows a confusion matrix for the test set\n",
    "    \n",
    "    roc_auc allows you to set how to calculate the roc_auc score: \n",
    "    'dec' for decision_function or 'proba' for predict_proba \n",
    "    If roc_auc == 'skip', then it ignores calculating the roc_auc_score\n",
    "    '''\n",
    "    # grab predictions\n",
    "    train_preds = estimator.predict(X_train)\n",
    "    test_preds = estimator.predict(X_test)\n",
    "    \n",
    "    # output needed for roc_auc_score\n",
    "    if roc_auc == 'skip': # skips calculating the roc_auc_score\n",
    "        train_out = False\n",
    "        test_out = False\n",
    "    elif roc_auc == 'dec': # not all classifiers have decision_function\n",
    "        train_out = estimator.decision_function(X_train)\n",
    "        test_out = estimator.decision_function(X_test)\n",
    "    elif roc_auc == 'proba':\n",
    "        train_out = estimator.predict_proba(X_train)[:, 1] # proba for the 1 class\n",
    "        test_out = estimator.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        raise Exception(\"The value for roc_auc should be 'skip', 'dec' or 'proba'.\")\n",
    "    \n",
    "    # print scores\n",
    "    print(\"Train Scores\")\n",
    "    print(\"------------\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_train, train_preds)}\")\n",
    "    print(f\"F1 Score: {f1_score(y_train, train_preds)}\")\n",
    "    if type(train_out) == np.ndarray: # checking for roc_auc\n",
    "        print(f\"ROC-AUC: {roc_auc_score(y_train, train_out)}\")\n",
    "    print(\"----\" * 5)\n",
    "    print(\"Test Scores\")\n",
    "    print(\"-----------\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, test_preds)}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, test_preds)}\")\n",
    "    if type(test_out) == np.ndarray:\n",
    "        print(f\"ROC-AUC: {roc_auc_score(y_test, test_out)}\")\n",
    "    \n",
    "    # plot test confusion matrix\n",
    "    plot_confusion_matrix(estimator, X_test, y_test, values_format=',.5g')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use that function with the val set!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion Time!\n",
    "\n",
    "What does it mean to decide between model types? What do we think best represents this data? What else might I want to explore or understand before deciding that?\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "Check out Aurélien Geron's notebook of an [end-to-end ml project](https://github.com/ageron/handson-ml2/blob/master/02_end_to_end_machine_learning_project.ipynb) on his GitHub repo based around his book [_Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems (2nd ed)_](https://www.oreilly.com/library/view/hands-on-machine-learning/9781491962282/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
